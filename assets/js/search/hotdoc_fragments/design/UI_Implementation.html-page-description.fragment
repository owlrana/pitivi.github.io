fragment_downloaded_cb({"url":"design/UI_Implementation.html#page-description","fragment":"This document does not reflect the existing codebase, but rather a\nroad map for future development, and a general introduction to the\nPiTiVi design philosophy.\nThe goal of the design is to build a UI which supports the following\nfeatures:\n(*) It is important to distinguish between a track, and a layer\nin application terminology. Existing video editors use the term\ntrack to refer to a UI object which represents a stream of video\nwith a sequence of sources. PiTiVi refers to this as a composition.\nThe term track in PiTiVi means a separate channel of output: for\nexample, audio and video are in separate tracks.\nThis is distinguished from the concept of a layer which is directly\nrelated to the notion of compositing. Within a track, sources have a\nproperty called priority which determines what will appear when the\nplay-head reaches a given position in the timeline. By default, the\nsource with the lowest numerical priority is displayed. Adding effects\nto a composition enables multiple sources to be composited together.\nPriority is used to determine which sources will be used by an effect as\ninput.\nPiTiVi relies heavily on MVC and Observer design patterns to decouple\nthe core of the application from the user interface. Core objects emit\nsignals which prompt changes in the UI. UI elements wrap core objects to\nmanipulate data, which in turn emit signals. The observer pattern allows\nthe user interface to listen for changes in the core without coupling\nthe core to the UI.\nIn core, we have our own pure-python implementation of “signals”. The\nuser interface depends on pygtk and pygoocanvas, both of which are based\non GObject. We use “receivers” to automatically connect appropriate\nsignal handler methods to objects which emit them.\nThe majority of the UI uses pygtk. The timeline portion also relies on\ngoocanvas. This section is about the pygoocanvas portion of the UI.\nObjects visible in the timeline will either descend from or mix-in the\nView class, available in the view module. Instances of the view class\ncreate an instance of Controller which handles low-level input events\nand translates these into higher-level commands which it passes onto the\nmodel.\nView objects appear exclusively in the time-line component of the UI.\nEach view represents some object in the current timeline. Views must\nupdate their appearance when the object they represent changes. While in\nmost cases, this will be accomplished by connecting to model signals, it\nis up to the individual view object to do this. No infrastructure is\nprovided by the View base class. In general, views should multiply from\nView and some subclass of goocanvas.Item. The controller code connects\nto specific signals, and expects that these signals will have the same\nsignature as defined in goocanvas.Item.\nViews provide a public interface for controlling appearance. There are 3\nindependent visual states:\nA fourth state, normal, is defined as being simultaneously unfocused,\ninactive, and deselected.\nView classes have a class attribute, Controller, which can be reference\nto BaseController. Views automatically instantiate and connect to an\ninstance of this class during initialization. Derived Views can redefine\nthis attribute to any subclass of Controller -- even one defined as an\ninner class -- if they wish to override default functionality. This\ndesign is intended to keep a tight integration between a View and its\nController.\nControllers provide a high-level public interface for handling the\nfollowing kinds of interaction\n\ndocument markers\ndocument keyframes\nexplain the concept of a receiver.\n\n\nbasic editing\nbasic effects\ncompositing\nmulti-track editing\nmulti-layer editing*\nmultiple selection\nnoun-verb interaction\ndirect manipulation wherever possible\nleaving behavior up to the core implementation\n\n\nfocused/unfocused\nactive/inactive\nselected/deselected.\n\n\nkey press events\nmouse clicks\nmouse drags\nfocus changes\n\n"});